{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../dataset'\n",
    "processed_path = '../processed/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate the txt file and process the picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = ['C.albicans',\n",
    "                'S.aureus',\n",
    "                'P.aeruginosa',\n",
    "                'E.coli',\n",
    "                'B.subtilis',\n",
    "                'Defect',\n",
    "                'Contamination']\n",
    "\n",
    "def genearte_txt(path):\n",
    "    # get the all json file\n",
    "    files = os.listdir(path)\n",
    "    for file in tqdm(files,total=len(files)):\n",
    "        text = []\n",
    "        if file.endswith('.json'):\n",
    "            pic_name = file.split('.')[0]\n",
    "            pic_path = pic_name + '.jpg'\n",
    "            pic_path = os.path.join(path, pic_path)\n",
    "            pic = cv2.imread(pic_path)\n",
    "            file_path = os.path.join(path, file)\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                annotations = data['labels']\n",
    "                for annotation in annotations:\n",
    "                    x = annotation['x']\n",
    "                    y = annotation['y']\n",
    "                    w = annotation['width']\n",
    "                    h = annotation['height']\n",
    "                    class_name = annotation['class']\n",
    "                    if class_name not in class_mapping:\n",
    "                        class_mapping.append(class_name)\n",
    "                    class_index = class_mapping.index(class_name)\n",
    "                    cx = x + w / 2\n",
    "                    cy = y + h / 2\n",
    "                    # get the relative position\n",
    "                    cx = cx / pic.shape[1]\n",
    "                    cy = cy / pic.shape[0]\n",
    "                    text.append((class_index,cx,cy,w/pic.shape[1],h/pic.shape[0]))\n",
    "            with open(os.path.join(processed_path,'labels', pic_name + '.txt'), 'w') as f:\n",
    "                for line in text:\n",
    "                    f.write(' '.join([str(x) for x in line]) + '\\n')\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21582/21582 [33:49<00:00, 10.63it/s] \n"
     ]
    }
   ],
   "source": [
    "genearte_txt('../dataset/train_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C.albicans',\n",
       " 'S.aureus',\n",
       " 'P.aeruginosa',\n",
       " 'E.coli',\n",
       " 'B.subtilis',\n",
       " 'Defect',\n",
       " 'Contamination']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_path = '../processed/test'\n",
    "def process_img(path):\n",
    "    files = os.listdir(path)\n",
    "    for file in tqdm(files,total=len(files)):\n",
    "        if file.endswith('.jpg'):\n",
    "            print(file)\n",
    "            pic_path = os.path.join(path, file)\n",
    "            pic = cv2.imread(pic_path)\n",
    "            pic = cv2.cvtColor(pic, cv2.COLOR_BGR2GRAY)\n",
    "            save_path = os.path.join(processed_path,'images', file)\n",
    "            # cv2.imwrite(file, pic)\n",
    "            cv2.imwrite(save_path, pic)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2698 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16364.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2698 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "process_img('../dataset/test_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21582/21582 [00:17<00:00, 1228.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 789, 27: 106, 43: 91, 6: 338, 46: 74, 50: 60, 28: 89, 3: 642, 4: 543, 0: 974, 103: 10, 36: 104, 18: 146, 40: 89, 5: 424, 12: 147, 118: 4, 131: 11, 165: 1, 230: 2, 13: 150, 49: 58, 61: 29, 31: 97, 52: 46, 22: 111, 8: 227, 138: 5, 42: 75, 78: 17, 41: 74, 89: 8, 106: 6, 56: 55, 47: 73, 37: 91, 148: 2, 59: 28, 23: 112, 39: 77, 1: 800, 87: 10, 16: 148, 15: 143, 20: 114, 139: 3, 33: 92, 93: 13, 24: 96, 30: 82, 55: 41, 7: 233, 38: 91, 51: 55, 14: 150, 21: 112, 9: 195, 91: 16, 32: 88, 119: 5, 95: 11, 67: 15, 29: 77, 26: 95, 70: 17, 11: 150, 153: 2, 259: 1, 81: 13, 10: 163, 126: 7, 35: 86, 63: 25, 109: 9, 74: 15, 65: 30, 34: 97, 45: 60, 25: 102, 54: 47, 62: 24, 60: 27, 48: 67, 73: 17, 17: 124, 98: 12, 57: 33, 84: 11, 159: 5, 190: 3, 90: 9, 69: 11, 58: 25, 79: 11, 110: 7, 19: 113, 44: 82, 150: 4, 71: 14, 121: 6, 221: 2, 282: 2, 83: 10, 203: 3, 53: 48, 80: 15, 122: 8, 124: 7, 92: 10, 107: 7, 213: 1, 101: 10, 76: 19, 102: 10, 125: 4, 105: 8, 96: 5, 77: 11, 252: 1, 149: 5, 64: 27, 104: 15, 111: 9, 130: 6, 179: 2, 66: 26, 140: 3, 86: 13, 226: 2, 147: 4, 120: 6, 181: 2, 136: 6, 117: 11, 154: 3, 142: 6, 97: 15, 214: 1, 114: 9, 72: 26, 115: 5, 68: 13, 253: 3, 160: 3, 162: 4, 284: 2, 235: 1, 143: 5, 82: 9, 135: 4, 272: 1, 240: 1, 185: 2, 88: 11, 132: 8, 99: 7, 75: 10, 161: 3, 112: 6, 223: 1, 172: 2, 287: 1, 215: 3, 196: 2, 94: 11, 158: 4, 156: 4, 258: 1, 212: 2, 184: 1, 255: 2, 85: 14, 173: 2, 261: 2, 204: 2, 100: 4, 281: 1, 167: 3, 299: 1, 177: 1, 169: 2, 123: 8, 197: 1, 198: 3, 145: 7, 250: 1, 164: 2, 279: 1, 242: 2, 246: 3, 192: 2, 288: 1, 155: 2, 206: 2, 168: 3, 170: 2, 201: 2, 116: 5, 188: 2, 268: 1, 144: 5, 225: 2, 183: 1, 108: 4, 224: 1, 146: 3, 234: 1, 129: 4, 285: 1, 191: 1, 137: 4, 194: 1, 232: 2, 174: 4, 133: 6, 127: 4, 152: 3, 175: 3, 300: 2, 249: 1, 151: 2, 171: 2, 286: 2, 294: 1, 267: 2, 134: 2, 297: 2, 289: 1, 263: 1, 222: 1, 251: 1, 238: 2, 163: 1, 113: 1, 241: 1, 141: 2, 260: 1, 157: 2, 210: 1, 202: 1, 280: 1, 231: 1, 266: 2, 128: 1, 166: 1, 216: 1, 189: 1, 186: 1, 176: 2, 182: 1, 217: 1, 209: 1, 243: 1, 247: 2, 195: 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = '../dataset/train_data'\n",
    "files = os.listdir(path)\n",
    "datamap = {}\n",
    "for file in tqdm(files,total=len(files)):\n",
    "    text = []\n",
    "    if file.endswith('.json'):\n",
    "        file_path = os.path.join(path, file)\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            num = data['colonies_number']\n",
    "            if num not in datamap:\n",
    "                datamap[num] =1\n",
    "            else:\n",
    "                datamap[num] += 1\n",
    "print(datamap)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "file ='../dataset/train_data/8421.json'\n",
    "path = '../dataset/train_data'\n",
    "pic_name = file.split('.')[0]\n",
    "pic_path = pic_name + '.jpg'\n",
    "pic_path = os.path.join(path, pic_path)\n",
    "pic = cv2.imread(pic_path)\n",
    "file_path = os.path.join(path, file)\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 3645, 3)\n"
     ]
    }
   ],
   "source": [
    "print(pic.shape)\n",
    "width = pic.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0113854595336076 0.513625 64\n"
     ]
    }
   ],
   "source": [
    "annotations = data['labels']\n",
    "for j,annotation in enumerate(annotations):\n",
    "    x = annotation['x']\n",
    "    y = annotation['y']\n",
    "    w = annotation['width']\n",
    "    h = annotation['height']\n",
    "    class_name = annotation['class']\n",
    "    cx = x + w / 2\n",
    "    cy = y + h / 2\n",
    "    # get the relative position\n",
    "    cx = cx / width\n",
    "    cy = cy / pic.shape[0]\n",
    "    if cx > 1 or cy > 1:\n",
    "        print(cx,cy,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': 'C.albicans',\n",
       " 'height': 19,\n",
       " 'id': 65,\n",
       " 'width': 19,\n",
       " 'x': 3677,\n",
       " 'y': 2045}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels'][64]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "novo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
